{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749b0ddf",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = https://project.lsst.org/sites/default/files/Rubin-O-Logo_0.png width=250 style=\"padding: 10px\"> \n",
    "<b>Introduction to Point Spread Function (PSF)</b> <br>\n",
    "Contact author(s): Andrés A. Plazas Malagón<br>\n",
    "Last verified to run:  09/5/2023 <br>\n",
    "LSST Science Pipelines version: w_2023_21  <br>\n",
    "Container Size: medium <br>\n",
    "Targeted learning level: intermediate <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1a210-d858-42fe-8591-570965b8be1a",
   "metadata": {},
   "source": [
    "**Description:** This tutorial offers a comprehensive guide to Point Spread Function (PSF) properties, covering topics such as retrieval from catalogs and images, kernel generation, image display, size calculations, wavelength dependence, and diagnostic statistics like correlation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a0baf5-51ad-40ec-8991-060a7b27c289",
   "metadata": {},
   "source": [
    "**Skills:** Use of the catalog data products for PSF studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393da88f-7978-4920-aa4a-a9830df6eed9",
   "metadata": {},
   "source": [
    "**LSST Data Products:**   DP0.2 collection: `2.2i/runs/DP0.2`. Dataset types: `calexp`, `deepCoadd`.  Catalogs: `dp02_dc2_catalogs.Object`, `dp02_dc2_catalogs.Source`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c67fab9-136a-4adc-bb42-142b91ab69dd",
   "metadata": {},
   "source": [
    "**Packages:** lsst.afw.image, lsst.afw.detection, lsst.rsp, lsst.daf.butler, lsst.geom, lsst.afw.display, lsst.analysis.tools, lsst.pipe.base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72b27f",
   "metadata": {},
   "source": [
    "**Credits:** Developed by Andrés A. Plazas Malagón in collaboration with Melissa Graham, Jeff Carlin, Douglas Tucker, and the Rubin Community Science Team for DP0.2. The `ImageExaminer` class, used for studying the PSF image profile and properties, is built upon the rapid-analysis code originally created by Merlin Fisher-Levine to characterize the Point Spread Function (PSF) of the Rubin Auxiliary Telescope LSST Atmospheric Transmission and Slitless Spectrograph (LATISS) images. The section on PSF size and its correlation function using the `treecorr` software is based on a Jupyter notebook authored by Claire-Alice Hebert. The section on PSF size histograms and their dependency on the central filter wavelength is derived from a Jupyter Notebook by Tianqing Zhang. The section on `rho` statistics using `lsst.analysis.tools` draws from a Jupyter Notebook by Arun Kannawadi.\n",
    "\n",
    "This notebook incorporates suggestions from the [Accessible Authoring Checklist](https://iota-school.github.io/accessibility_hackathon/hack#checklist) and utilizes NASA's Astrophysics Data System Bibliographic Services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e91cbf-ab7f-4e26-9276-b00299d6065e",
   "metadata": {},
   "source": [
    "**Get Support:**\n",
    "Find DP0-related documentation and resources at <a href=\"https://dp0-2.lsst.io\">dp0-2.lsst.io</a>. Questions are welcome as new topics in the <a href=\"https://community.lsst.org/c/support/dp0\">Support - Data Preview 0 Category</a> of the Rubin Community Forum. Rubin staff will respond to all questions posted there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc73be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "In the context of astronomical surveys, such as the Vera C. Rubin Legacy Survey of Space and Time (LSST), a significant objective is to extract cosmological information by scrutinizing subtle deviations in the shapes and orientations of galaxies. These deviations are caused by gravitational lensing from large-scale structures in the foreground. However, the observed shapes of galaxies are not solely influenced by the gravitational lensing effects of the universe's large-scale structure (referred to as \"cosmic shear\"), but also by a combined blurring effect known as the point spread function (PSF). The PSF arises from various factors such as atmospheric conditions (for ground-based instruments), telescope optics, and the image sensor.\n",
    "\n",
    "The PSF can be understood as a function that describes how a bundle of rays, initially converging on a single point, spreads out spatially around that point. To accurately characterize the PSF, it is common to analyze the observed images of stars, which act as point sources before being distorted by the PSF. This analysis helps determine the convolution kernel, representing the size and shape of the blurring effect caused by the PSF. Accurate PSF modeling is crucial because any inaccuracies can lead to erroneous conclusions about fundamental aspects of the universe, such as the properties of dark matter and dark energy. Therefore, understanding and characterizing the PSF is essential to properly interpret and extract reliable cosmological information from astronomical observations.\n",
    "\n",
    "This tutorial investigates the properties of the Point Spread Function using the DP0.2 dataset. It is composed of the following sections:\n",
    "\n",
    "- Section 2 produces an image of the PSF model at a specific location in `calexp` and `deepCoadd` images. It then demonstrates how to calculate PSF profiles and contours, along with other properties such as size.\n",
    "\n",
    "- Section 3 calculates and displays the size of the PSF in a particular photometric band (`i`) as a function of sky location. It also computes the size-size two-point correlation function (autocorrelation) using the `treecorr` software. This software is widely used in state-of-the-art weak lensing analyses to derive cosmological parameters. These calculations are performed using both `calexp` and `deepCoadd` images.\n",
    "\n",
    "- Section 4 illustrates one chromatic dependence of the PSF: the wavelength dependence of the PSF size.\n",
    "\n",
    "- Section 5 calculates the `rho` statistics, a series of two-point correlation functions used to diagnose the quality of a PSF model for weak lensing analyses. This calculation is done using the `lsst.afw.analysis.tools` framework.\n",
    "\n",
    "#### Additional Resources\n",
    "\n",
    "Review article: [Point Spread Function Modelling for Astronomical Telescopes: A Review Focused on Weak Gravitational Lensing Studies](https://ui.adsabs.harvard.edu/abs/2023arXiv230607996L/abstract)\n",
    "\n",
    "[Treecorr Documentation](https://rmjarvis.github.io/TreeCorr/_build/html/index.html)\n",
    "\n",
    "Chromatic effects of the PSF:\n",
    "\n",
    "- Impact of Differential Chromatic Refraction (DCR) on weak lensing:  \n",
    " [Plazas and Bernstein 2012](https://ui.adsabs.harvard.edu/abs/2012PASP..124.1113P/abstract)\n",
    "    \n",
    "- Impact of DCR on Supernovae measurements: \n",
    "[Lee et al. 2023](https://ui.adsabs.harvard.edu/abs/2023AJ....165..222L/abstract)\n",
    "    \n",
    "- Impact of DCR, wavelength dependence of seeing, and other chromatic effects on weak lensing:\n",
    "[Meyers and Burchat 2015](https://ui.adsabs.harvard.edu/abs/2015ApJ...807..182M/abstract)\n",
    "\n",
    "PSF modeling and null tests for galaxy surveys, including `rho` statistics:\n",
    "\n",
    "-  [Dark Energy Survey Y3 Results: Point Spread Function Modeling](https://ui.adsabs.harvard.edu/abs/2021MNRAS.501.1282J/abstract)\n",
    "-  [The Three-Year Shear Catalog of the Subaru Hyper Suprime-Cam SSP Survey](https://ui.adsabs.harvard.edu/abs/2022PASJ...74..421L/abstract)\n",
    "\n",
    "PSF in coadded images: \n",
    "\n",
    "- [Mandelbaum et al. 2022](https://ui.adsabs.harvard.edu/abs/2023OJAp....6E...5M/abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36f107",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1. Package Imports\n",
    "\n",
    "The [matplotlib](https://matplotlib.org/) (and especially sublibrary `matplotlib.pyplot`), [numpy](http://www.numpy.org/), [scipy](https://scipy.org/), and [astropy](http://www.astropy.org/) libraries are widely used Python libraries for plotting, scientific computing, scientific analysis, and astronomical data analysis.\n",
    "\n",
    "The `lsst.rsp` package provides access to the Table Access Protocol (TAP) service for queries to the DP0 catalogs.\n",
    "\n",
    "The `lsst.afw.image` provide visualization tools.\n",
    "\n",
    "The `lsst.afw.display` library provides access to image visualization routines and the `lsst.daf.butler` library is used to access data products via the butler.\n",
    "\n",
    "The `lsst.afw.analysis.tools` library provides acces to analysis tools.\n",
    "\n",
    "The `lsst.geom` library provides the representation of a 2D coordinate `Point2D`.\n",
    "\n",
    "The `lsst.pipe.base` library provides access to the `lsst.pipe.base.Struct` container.\n",
    "\n",
    "[treecorr](https://rmjarvis.github.io/TreeCorr/_build/html/index.html) by [Jarvis et al. 2004](https://ui.adsabs.harvard.edu/abs/2004MNRAS.352..338J/abstract) is a widely used tool for fast correlations measurements based on a ball tree method (similar to a [k-d tree](https://en.wikipedia.org/wiki/K-d_tree)). In particular, it is widely used in state-of-the-art weak lensing cosmological analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d597c54-cc18-49c9-a3fa-2fbd76a9c6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%flake8_on\n",
    "import logging\n",
    "logging.getLogger(\"flake8\").setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185358a-4c15-4b04-8e3d-13083191ee72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import treecorr\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib import cm\n",
    "from numpy.linalg import norm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.pipe.base as pipeBase\n",
    "from lsst.rsp import get_tap_service\n",
    "from lsst.geom import Point2D, radToDeg, SpherePoint, degrees\n",
    "from lsst.analysis.tools.atools import RhoStatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa240aaf-d675-4d72-bb68-d736200f4980",
   "metadata": {},
   "source": [
    "### 1.2 Functions and Parameters Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd7f04-f3d2-4f92-9927-acb9f47fe772",
   "metadata": {},
   "source": [
    "The following cell will set a standard figure size and `afwDisplay` backend to use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f35be0-b960-46d7-bc1e-b875f641fd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "afwDisplay.setDefaultBackend('matplotlib')\n",
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b0a82-9fb4-46fb-bc9b-2db4c04497ba",
   "metadata": {},
   "source": [
    "The following hidden cell introduces the conversion factor between the standard deviation of a one-dimensional Gaussian profile and its full-width at half maximum (FWHM), a function characterized by a one-dimensional Gaussian profile, a power-law function, and the class `ImageExaminer`. The `ImageExaminer` class is utilized in section 2.3, \"PSF Properties for Rapid Analysis,\" to scrutinize the image of the Point Spread Function at a specific location.\n",
    "\n",
    "This class is constructed based on a [similar class](https://github.com/lsst-sitcom/summit_utils/blob/main/python/lsst/summit/utils/imageExaminer.py) developed by Merlin Fisher-Levine. The original class was designed for swift [analysis of images](https://roundtable.lsst.codes/rubintv/summit/auxtel/im_current) captured by the Rubin Auxiliary Telescope using the LATISS instrument, with the results typically displayed on [Rubin TV](https://roundtable.lsst.codes/rubintv). The `ImageExaminer` class includes various methods, such as producing contour, surface, and radial plots, along with calculating specific statistics of interest, including the PSF size (according to specific definitions of size).\n",
    "\n",
    "Furthermore, the hidden cell incorporates auxiliary functions aimed at plotting instances of the `ImageExaminer` class and computing the properties of a given PSF model at a specific point.\n",
    "\n",
    "To unveil the content of the hidden cell, opt for \"View\" from the menu bar, then select \"Expand Selected Code.\" Alternatively, you can click on the vertical line adjacent to the cell or on the three dots that signify the cell's hidden status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d654417-a7d2-4a2c-9846-de3ee6bcbafb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SIGMATOFWHM = 2.0*np.sqrt(2.0*np.log(2.0))\n",
    "\n",
    "\n",
    "def gauss(x, a, x0, sigma):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "\n",
    "def power(lam, a, b):\n",
    "    return a*lam**(-b)\n",
    "\n",
    "\n",
    "class ImageExaminer():\n",
    "    \"\"\"Class to examine PSF image properties.\n",
    "    This is a simplified version---with minor modifications---of the\n",
    "    code in\n",
    "    https://github.com/lsst-sitcom/summit_utils/blob/main/python/lsst/summit/utils/imageExaminer.py\n",
    "    \"\"\"\n",
    "    cutoutMappings = {\"fitAmp\": \"Radial fitted amp\",\n",
    "                      \"fitGausMean\": \"Radial fitted position\",\n",
    "                      \"fitFwhm\": \"Radial fitted FWHM\",\n",
    "                      \"eeRadius50\": \"50% flux radius\",\n",
    "                      \"eeRadius80\": \"80% flux radius\",\n",
    "                      \"eeRadius90\": \"90% flux radius\"}\n",
    "\n",
    "    def __init__(self, exp, *, centroid=None, boxHalfSize=None):\n",
    "        self.exp = exp\n",
    "        self.centroid = centroid\n",
    "        self.data = exp.array\n",
    "        xlen, ylen = self.data.shape\n",
    "        if centroid is None:\n",
    "            self.centroid = np.array([xlen/2, ylen/2])\n",
    "        else:\n",
    "            self.centroid = centroid\n",
    "        if boxHalfSize is None:\n",
    "            self.boxHalfSize = xlen // 2\n",
    "        else:\n",
    "            self.boxHalfSize = boxHalfSize\n",
    "        self.xx, self.yy = self.getMeshGrid(self.data)\n",
    "        self.imStats = pipeBase.Struct()\n",
    "        self.radialAverageAndFit()\n",
    "\n",
    "    def plotSurface(self, ax=None, useColor=True):\n",
    "        \"\"\"Make the surface plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : `maplotlib.axes`, optional.\n",
    "            If ``None`` a new figure is created. Supply axes\n",
    "            if including this as a subplot.\n",
    "        useColor : `bool`, optional.\n",
    "            Plot at as a surface if ``True``, else plot as a\n",
    "            wireframe.\n",
    "        \"\"\"\n",
    "        plotDirect = False\n",
    "        if not ax:\n",
    "            fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"},\n",
    "                                   figsize=(10, 10))\n",
    "            plotDirect = True\n",
    "\n",
    "        if useColor:\n",
    "            _ = ax.plot_surface(self.xx, self.yy, self.data,\n",
    "                                cmap=cm.plasma, linewidth=1,\n",
    "                                antialiased=True, color='k', alpha=0.9)\n",
    "        else:\n",
    "            _ = ax.plot_wireframe(self.xx, self.yy,\n",
    "                                  self.data, cmap=cm.gray,  # noqa F841\n",
    "                                  linewidth=1, antialiased=True, color='k')\n",
    "\n",
    "        ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "        ax.zaxis.set_major_formatter('{x:,.0f}')\n",
    "        ax.set_title(\"Surface plot\")\n",
    "        ax.set_xlabel('x (pix)')\n",
    "        ax.set_ylabel('y (pix)')\n",
    "\n",
    "        if plotDirect:\n",
    "            plt.show()\n",
    "\n",
    "    def plotContours(self, ax=None, nContours=10):\n",
    "        \"\"\"Make the contour plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : `maplotlib.axes`, optional\n",
    "            If ``None`` a new figure is created. Supply axes\n",
    "            if including this as a subplot.\n",
    "        nContours : `int`, optional\n",
    "            The number of contours to use.\n",
    "        \"\"\"\n",
    "        plotDirect = False\n",
    "        if not ax:\n",
    "            fig = plt.figure(figsize=(8, 8))  # noqa F841\n",
    "            ax = plt.subplot(111)\n",
    "            plotDirect = True\n",
    "\n",
    "        vmin = np.percentile(self.data, 0.1)\n",
    "        vmax = np.percentile(self.data, 99.9)\n",
    "        lvls = np.linspace(vmin, vmax, nContours)\n",
    "        _ = ax.contour(self.xx, self.yy,\n",
    "                       self.data, levels=lvls)\n",
    "\n",
    "        ax.tick_params(which=\"both\", direction=\"in\",\n",
    "                       top=True, right=True, labelsize=8)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_title(\"Contour plot\")\n",
    "        ax.set_xlabel('x (pix)')\n",
    "        ax.set_ylabel('y (pix)')\n",
    "\n",
    "        if plotDirect:\n",
    "            plt.show()\n",
    "\n",
    "    def plotRowColSlices(self, ax=None):\n",
    "        \"\"\"Make the row and column slice plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : `maplotlib.axes`, optional\n",
    "            If ``None`` a new figure is created. Supply axes\n",
    "            if including this as a subplot.\n",
    "        \"\"\"\n",
    "        rowSlice = self.data[self.boxHalfSize, :]\n",
    "        colSlice = self.data[:, self.boxHalfSize]\n",
    "\n",
    "        plotDirect = False\n",
    "        if not ax:\n",
    "            ax = plt.subplot(111)\n",
    "            plotDirect = True\n",
    "\n",
    "        xs = range(-1*self.boxHalfSize, self.boxHalfSize+1)\n",
    "        ax.plot(xs, rowSlice, '--', label='Row plot')\n",
    "        ax.plot(xs, colSlice, label='Column plot')\n",
    "        ax.set_ylabel('Flux (ADU)')\n",
    "        ax.set_xlabel('Radius (pix)')\n",
    "        ax.set_aspect(1.0/ax.get_data_ratio(),\n",
    "                      adjustable='box')\n",
    "        ax.legend()\n",
    "        ax.set_title(\"PSF slices\")\n",
    "        if plotDirect:\n",
    "            plt.show()\n",
    "\n",
    "    def plotRadialAverage(self, ax=None):\n",
    "        \"\"\"Make the radial average plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : `maplotlib.axes`, optional\n",
    "            If ``None`` a new figure is created. Supply axes\n",
    "            if including this as a subplot.\n",
    "        \"\"\"\n",
    "        plotDirect = False\n",
    "        if not ax:\n",
    "            ax = plt.subplot(111)\n",
    "            plotDirect = True\n",
    "\n",
    "        distances = self.radialDistances\n",
    "        values = self.radialValues\n",
    "        pars = (self.imStats.fitAmp,\n",
    "                self.imStats.fitGausMean,\n",
    "                self.imStats.fitFwhm / SIGMATOFWHM)\n",
    "\n",
    "        fitFailed = np.isnan(pars).any()\n",
    "\n",
    "        ax.plot(distances, values, 'x', label='Radial average')\n",
    "        if not fitFailed:\n",
    "            fitline = gauss(distances, *pars)\n",
    "            ax.plot(distances, fitline, label=\"Gaussian fit\")\n",
    "\n",
    "        ax.set_ylabel('Flux (ADU)')\n",
    "        ax.set_xlabel('Radius (pix)')\n",
    "        ax.set_aspect(1.0/ax.get_data_ratio(),\n",
    "                      adjustable='box')\n",
    "        ax.legend()\n",
    "        ax.set_title(\"Azimuthally-averaged radial profile.\")\n",
    "\n",
    "        if plotDirect:\n",
    "            plt.show()\n",
    "\n",
    "    def radialAverageAndFit(self):\n",
    "        \"\"\"Calculate flux vs radius from the star's centroid and fit the width.\n",
    "\n",
    "        Calculate the flux vs distance from the star's\n",
    "        centroid and fit a Gaussian to get a measurement of the width.\n",
    "\n",
    "        Also calculates the various encircled energy metrics.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Nothing is returned, but sets many value in the class.\n",
    "        \"\"\"\n",
    "        xlen, ylen = self.data.shape\n",
    "        center = np.array([xlen/2, ylen/2])\n",
    "        distances = []\n",
    "        values = []\n",
    "\n",
    "        for i in range(xlen):\n",
    "            for j in range(ylen):\n",
    "                value = self.data[i, j]\n",
    "                dist = norm((i, j) - center)\n",
    "                if dist > xlen//2:\n",
    "                    # clip to box size, we don't need a factor\n",
    "                    # of sqrt(2) extra\n",
    "                    continue\n",
    "                values.append(value)\n",
    "                distances.append(dist)\n",
    "\n",
    "        peakPos = 0\n",
    "        amplitude = np.max(values)\n",
    "        width = 10\n",
    "\n",
    "        bounds = ((0, 0, 0), (np.inf, np.inf, np.inf))\n",
    "\n",
    "        try:\n",
    "            pars, pCov = curve_fit(gauss, distances, values,\n",
    "                                   [amplitude, peakPos, width],\n",
    "                                   bounds=bounds)\n",
    "            pars[0] = np.abs(pars[0])\n",
    "            pars[2] = np.abs(pars[2])\n",
    "        except RuntimeError:\n",
    "            pars = None\n",
    "            self.imStats.fitAmp = np.nan\n",
    "            self.imStats.fitGausMean = np.nan\n",
    "            self.imStats.fitFwhm = np.nan\n",
    "\n",
    "        if pars is not None:\n",
    "            self.imStats.fitAmp = pars[0]\n",
    "            self.imStats.fitGausMean = pars[1]\n",
    "            self.imStats.fitFwhm = pars[2] * SIGMATOFWHM\n",
    "\n",
    "        self.radialDistances = distances\n",
    "        self.radialValues = values\n",
    "\n",
    "        # calculate encircled energy metric too\n",
    "        # sort distances and values in step by distance\n",
    "        d = np.array([(r, v) for (r, v) in sorted(zip(self.radialDistances,\n",
    "                                                      self.radialValues))])\n",
    "        self.radii = d[:, 0]\n",
    "        values = d[:, 1]\n",
    "        self.cumFluxes = np.cumsum(values)\n",
    "        self.cumFluxesNorm = self.cumFluxes/np.max(self.cumFluxes)\n",
    "        self.imStats.eeRadius50 = self.getEncircledEnergyRadius(50)\n",
    "        self.imStats.eeRadius80 = self.getEncircledEnergyRadius(80)\n",
    "        self.imStats.eeRadius90 = self.getEncircledEnergyRadius(90)\n",
    "\n",
    "        return\n",
    "\n",
    "    def plotCurveOfGrowth(self, ax=None):\n",
    "        \"\"\"Make the encircled energy plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : `maplotlib.axes`, optional\n",
    "            If ``None`` a new figure is created. Supply axes\n",
    "            if including this as a subplot.\n",
    "        \"\"\"\n",
    "        plotDirect = False\n",
    "        if not ax:\n",
    "            ax = plt.subplot(111)\n",
    "            plotDirect = True\n",
    "\n",
    "        ax.plot(self.radii, self.cumFluxesNorm, markersize=10)\n",
    "        ax.set_ylabel('Encircled flux (%)')\n",
    "        ax.set_xlabel('Radius (pix)')\n",
    "\n",
    "        ax.set_aspect(1.0/ax.get_data_ratio(),\n",
    "                      adjustable='box')\n",
    "        ax.set_title(\"Encircled flux\")\n",
    "\n",
    "        if plotDirect:\n",
    "            plt.show()\n",
    "\n",
    "    def plotStats(self, ax, lines):\n",
    "        \"\"\"Make the stats box 'plot'.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : `maplotlib.axes`\n",
    "            Axes to use.\n",
    "        lines : `list` of `str`\n",
    "            The data to include in the text box\n",
    "        \"\"\"\n",
    "        text = \"\\n\".join([line for line in lines])\n",
    "\n",
    "        stats_text = AnchoredText(text, loc=\"center\", pad=0.5,\n",
    "                                  prop=dict(size=14, ma=\"left\",\n",
    "                                            backgroundcolor=\"white\",\n",
    "                                            color=\"black\", family='monospace'))\n",
    "        ax.add_artist(stats_text)\n",
    "        ax.axis('off')\n",
    "\n",
    "    def getStarBoxData(self):\n",
    "        \"\"\"Get the image data for the star.\n",
    "\n",
    "        Calculates the maximum valid box, and uses that\n",
    "        to return the image data, setting self.starBbox\n",
    "        as this method changes the bbox.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        data : `np.array`\n",
    "            The image data\n",
    "        \"\"\"\n",
    "        bbox = self._calcBbox(self.centroid)\n",
    "        self.starBbox = bbox\n",
    "\n",
    "        return self.exp.image[bbox].array\n",
    "\n",
    "    def getMeshGrid(self, data):\n",
    "        \"\"\"Get the meshgrid for a data array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `np.array`\n",
    "            The image data array.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xxyy : `tuple` of `np.array`\n",
    "            The xx, yy as calculated by np.meshgrid\n",
    "        \"\"\"\n",
    "        xlen, ylen = data.shape\n",
    "        xx = np.arange(-1*xlen/2, xlen/2, 1)\n",
    "        yy = np.arange(-1*ylen/2, ylen/2, 1)\n",
    "        xx, yy = np.meshgrid(xx, yy)\n",
    "        return xx, yy\n",
    "\n",
    "    def getEncircledEnergyRadius(self, percentage):\n",
    "        \"\"\"Radius in pixels with the given percentage of\n",
    "            encircled energy.\n",
    "\n",
    "        100% is at the boxHalfWidth dy definition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        percentage : `float` or `int`\n",
    "            The percentage threshold to return.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        radius : `float`\n",
    "            The radius at which the ``percentage`` threshold\n",
    "            is crossed.\n",
    "        \"\"\"\n",
    "        return self.radii[np.argmin(\n",
    "            np.abs((percentage/100)-self.cumFluxesNorm))]\n",
    "\n",
    "    @staticmethod\n",
    "    def translateStats(imStats, mappingDict):\n",
    "        \"\"\"Create the text for the stats box from the stats\n",
    "            themselves.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        imStats : `lsst.pipe.base.Struct`\n",
    "            A container with attributes containing measurements\n",
    "            and statistics for the image.\n",
    "        mappingDict : `dict` of `str`\n",
    "            A mapping from attribute name to name for rendereding\n",
    "            as text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        lines : `list` of `str`\n",
    "            The translated lines of text.\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        for k, v in mappingDict.items():\n",
    "            try:\n",
    "                value = getattr(imStats, k)\n",
    "            except Exception:\n",
    "                lines.append(\"\")\n",
    "                continue\n",
    "\n",
    "            if type(value) == float or isinstance(value, np.floating):\n",
    "                value = f\"{value:,.3f}\"\n",
    "            if k == 'centroid':\n",
    "                value = f\"{value[0]:.1f}, {value[1]:.1f}\"\n",
    "            lines.append(f\"{v} = {value}\")\n",
    "        return lines\n",
    "\n",
    "\n",
    "def get_psf_properties(psf, point):\n",
    "    \"\"\"Function to obtain PSF properties.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    psf : `lsst.meas.extensions.psfex.PsfexPsf`\n",
    "        PSF object.\n",
    "    point : `lsst.geom.Point2D`\n",
    "        Coordinate where the PSF is being evaluated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        sigma : `float`\n",
    "            PSF determinat radius from SDDS adaptive\n",
    "            moments matrix.\n",
    "        ap_flux : `float`\n",
    "            PSF flux from aperture photometry weighted\n",
    "            by a sinc function.\n",
    "        peak : `float`\n",
    "            Peak PSF value.\n",
    "        dims : `lsst.geom.ExtendI`\n",
    "            PSF postage stamp dimensions.\n",
    "    \"\"\"\n",
    "    sigma = psf.computeShape(point).getDeterminantRadius()\n",
    "    ap_flux = psf.computeApertureFlux(radius=sigma, position=point)\n",
    "    peak = psf.computePeak(position=point)\n",
    "    dims = psf.computeImage(point).getDimensions()\n",
    "\n",
    "    print(f\"PSF size: {sigma:.4} pix \\n\"\n",
    "          f\"PSF flux from aperture photometry: {ap_flux:.4} \\n\"\n",
    "          f\"Peak PSF value: {peak:.4} \\n\"\n",
    "          f\"PSF dimensions: {dims} \\n\")\n",
    "\n",
    "    return (sigma, ap_flux, peak, dims)\n",
    "\n",
    "\n",
    "def plotPsfImageExaminer(psfImageExaminer):\n",
    "    \"\"\"Function to plot `ImageExaminer` instances.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    psfImageExaminer: `ImageExaminer`\n",
    "        `ImageExaminer` object.\n",
    "    \"\"\"\n",
    "    figsize = 6\n",
    "    fig = plt.figure(figsize=(figsize*2, 3*figsize))\n",
    "\n",
    "    axSurface = fig.add_subplot(321, projection='3d')\n",
    "    axContour = fig.add_subplot(322)\n",
    "    axStats = fig.add_subplot(323)\n",
    "    axSlices = fig.add_subplot(324)\n",
    "    axRadial = fig.add_subplot(325)\n",
    "    axEncircled = fig.add_subplot(326)\n",
    "\n",
    "    psfImageExaminer.plotSurface(axSurface)\n",
    "    psfImageExaminer.plotContours(axContour)\n",
    "    psfImageExaminer.plotRowColSlices(axSlices)\n",
    "    psfImageExaminer.plotRadialAverage(axRadial)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"\\n     ---- Cutout ----\")\n",
    "    lines.extend(psfImageExaminer.translateStats(\n",
    "        psfImageExaminer.imStats,\n",
    "        psfImageExaminer.cutoutMappings))\n",
    "\n",
    "    psfImageExaminer.plotStats(axStats, lines)\n",
    "    psfImageExaminer.plotCurveOfGrowth(axEncircled)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54dfd24-7ab3-4a8a-a966-0ab7e08d1ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. PSF image manipulation in `calexp` and `deepCoadd` images.\n",
    "\n",
    "The initial stage in processing LSST science observations involves Instrument Signature Removal (ISR). This encompasses fundamental detrending operations like flat-fielding, bias subtraction, fringe correction, and rectification of flawed and oversaturated pixels. Subsequently, the focus shifts to characterizing single-epoch direct images, constructing models that depict the observational system and its conversion of the true celestial scene into the observed image. This process encompasses background subtraction, PSF modeling, addressing cosmic ray effects, applying aperture corrections, and source measurement. After segregating stars and galaxies, the PSF model in single-epoch images is assembled using data from a star catalog. The LSST Science Pipelines have transitioned to using the [PIFF (PSF in the Full-Field of View)](https://rmjarvis.github.io/Piff/_build/html/index.html) code for PSF modeling in the full field of view, replacing the Point Spread Function Extractor, [PSFEx](https://ui.adsabs.harvard.edu/abs/2013ascl.soft01001B/abstract), software. However, the current approach to PSF coaddition is somewhat simplified and not optimally suited for weak lensing research. When the PSF model is requested at a specific point in a coadded image, all the PSF models from the single-epoch images that constitute that coadd are aggregated with the same weighting scheme used for creating the coadded image. The LSST Science Pipelines are in the process of implementing a more robust and clearly defined PSF coaddition procedure (as discussed in [Mandelbaum et al. 2022](https://ui.adsabs.harvard.edu/abs/2023OJAp....6E...5M/abstract)), based on measurements from coadded regions known as \"cell-based coadds\" (detailed in [Sheldon et al. 2023](https://ui.adsabs.harvard.edu/abs/2023OJAp....6E..17S/abstract)).\n",
    "\n",
    "In the forthcoming sections, we will generate an image of the PSF model at a specific location within both a `calexp` and a `deepCoadd` image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af207cd0-3eb8-49d0-be1f-85f078ca9380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:27:20.994415Z",
     "iopub.status.busy": "2023-07-05T16:27:20.993404Z",
     "iopub.status.idle": "2023-07-05T16:27:20.997680Z",
     "shell.execute_reply": "2023-07-05T16:27:20.996991Z",
     "shell.execute_reply.started": "2023-07-05T16:27:20.994378Z"
    },
    "tags": []
   },
   "source": [
    "#### 2.1 PSF in `calexp` images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfbb0ef-2e5c-44e3-a848-ec9f01544571",
   "metadata": {},
   "source": [
    "Define the Butler instance for DP0.2 and select a particular `calexp` image. We will pass the `visit` and `detector` numbers in order to uniquely constrain the image, and will visualize the imaga afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b41fed-5237-434e-ae97-5ef8c3805531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = 'dp02'\n",
    "collections = '2.2i/runs/DP0.2'\n",
    "butler = dafButler.Butler(config, collections=collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf8d6d-4df2-45e6-9ceb-cf95887e527b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetType = 'calexp'\n",
    "dataId = {'visit': 192350, 'detector': 175}\n",
    "calexp = butler.get(datasetType, dataId=dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbe0819-eba3-4006-9e1b-4f8d823525e2",
   "metadata": {},
   "source": [
    "The following plot is a 2D image of the `calexp` from the previous butler query, in pixel coordinates ranging from 0 to 4000 pixels in both axes, and with a contrast bar ranging from -300 to 400 digital units. Point and extended sources are scattered around the image. We will retrieve PSF models at particular points in this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774d0f6-cd45-40bb-86ff-9a19ab1f64aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "display = afwDisplay.Display(frame=fig)\n",
    "display.scale('asinh', 'zscale')\n",
    "display.mtv(calexp.image)\n",
    "plt.title(f'Calexp. dataID: {dataId}')\n",
    "plt.xlabel('x (pix)')\n",
    "plt.ylabel('y (pix)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322b7c3-e80d-4379-8413-e6c7abac0f74",
   "metadata": {},
   "source": [
    "We will use `computeKernelImage` to display the pixel-based model of the PSF at a particular point with coordinates `(x, y) = (2000, 3500)` (denoted by the `point_tuple` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbca3f9-9404-4716-acab-0aec70ee10ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "point_tuple = (2000, 3500)\n",
    "point_image = Point2D(point_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4776a6a1-07df-4c20-8645-3f11980a54c5",
   "metadata": {},
   "source": [
    "In the following cell, we extract the PSF model from the exposure information, obtained from the calexp object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd4ddb-73d5-4734-bbc0-c69afa149d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info_calexp = calexp.getInfo()\n",
    "psf_calexp = info_calexp.getPsf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b5c3b-a46f-4432-a09e-b9aac1022f90",
   "metadata": {},
   "source": [
    "We are now prepared to employ computeKernelImage to evaluate the PSF model at the location defined in the point_tuple variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a5047-16b4-4af0-a989-50e98561ca5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psf_calexp_kernel = psf_calexp.computeKernelImage(point_image)\n",
    "first_psf_image_calexp = psf_calexp_kernel.convertF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa19867-59a3-4bc2-969d-a09a3fa1631d",
   "metadata": {},
   "source": [
    "The subsequent plot depicts a postage stamp or cut-out of a PSF model extracted from a `calexp` image using the `computeKernelImage` function. The PSF is centered at the origin, and the stamp is rectangular, encompassing 40 pixels and spanning from negative 20 to positive 20 pixels on each side. The color contrast bar spans a range from approximately negative 0.0002 to about 0.0003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8e49b-fb44-4d20-ae72-0e1c816cb49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "afw_display = afwDisplay.Display()\n",
    "afw_display.scale('asinh', 'zscale')\n",
    "afw_display.mtv(first_psf_image_calexp)\n",
    "plt.title(f'PSF model in calexp at {point_image} using computeKernelImage')\n",
    "plt.xlabel('x (pix)')\n",
    "plt.ylabel('y (pix)')\n",
    "plt.gca().axis('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991693c-b950-4b03-a396-649a7527983b",
   "metadata": {},
   "source": [
    "Note that the image coordinates are centered at the origin of the image. The coordinates of this origin point are (0,0), resulting in negative coordinates for the lower left point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c6f7e-ead2-44d1-8a52-5fbb8fba61a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(first_psf_image_calexp.getXY0())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343915c-88e7-4980-b00b-3e77f67a7655",
   "metadata": {},
   "source": [
    "Now, instead of using `computeKernelImage`, we will utilize `computeImage`. The former positions the PSF center at the center of the central pixel within the stamp or cutout (`computeKernelImage`). On the other hand, the latter (`computeImage`) allows the PSF center to be placed at any arbitrary location. To achieve this, we require the astrometric solution, often referred to as the \"World Coordinate System\" (WCS) in the code, which maps pixel coordinates to sky coordinates and can also be obtained form the exposure information, as the PSF model. The \"WCS\" nomenclature is used for historical reasons. Note also that we need to convert the `point_tuple` variable into an `lsst.geom.Point2D` object first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309acb1-4213-4817-b64c-649557f35dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wcs_calexp = info_calexp.getWcs()\n",
    "point_object = Point2D(point_tuple)\n",
    "second_psf_image_calexp = psf_calexp.computeImage(point_object).convertF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3decc-a8e3-4f14-aabc-06f7a03bbe72",
   "metadata": {},
   "source": [
    "The following plot shows a postage stamp or cut-out of a PSF model from a `calexp`, obtained using `computeKernelImage`. The PSF is centered around (2000, 3500), and the stamp is rectangular, with a size of 40 pixels, ranging from 1980 to 2020 pixels on the `x` axis and from about 3480 to 3520 on the `y` axis. The contrast bar ranges from negative 0.0002 to about 0.0003. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23265383-a8df-4afe-add5-fc5499dd6c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "afw_display = afwDisplay.Display()\n",
    "afw_display.scale('asinh', 'zscale')\n",
    "afw_display.mtv(second_psf_image_calexp)\n",
    "plt.title(f'PSF model in calexp at {point_image} using computeImage')\n",
    "plt.xlabel('x (pix)')\n",
    "plt.ylabel('y (pix)')\n",
    "plt.gca().axis('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc5b3a-b2e2-4642-9bad-29fbb16a6259",
   "metadata": {},
   "source": [
    "Check again the coordinates for the lower left point in the previous image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca44e9b-1024-466e-82e5-35077156f11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(second_psf_image_calexp.getXY0())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f0cf4-70cc-4ecc-8526-160ad883eea6",
   "metadata": {},
   "source": [
    "Use now one of the helper functions we defined earlier — `get_psf_properties` — to calculate some PSF properties at a particular point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9f73e-7521-4062-be18-5d4657e1063c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "props = get_psf_properties(psf_calexp, point_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c731c48f-3126-4ca9-9bb5-b9549b0b2cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T18:22:30.461406Z",
     "iopub.status.busy": "2023-07-05T18:22:30.460243Z",
     "iopub.status.idle": "2023-07-05T18:22:30.469955Z",
     "shell.execute_reply": "2023-07-05T18:22:30.469108Z",
     "shell.execute_reply.started": "2023-07-05T18:22:30.461368Z"
    },
    "tags": []
   },
   "source": [
    "#### 2.2 PSF in `deepCoadd` images.\n",
    "\n",
    "When conducting multi-epoch surveys for static-sky science, the traditional method involves creating coadds. This process entails resampling images from different observations onto a common grid and averaging them to generate a single, deeper image known as a `deepCoadd`. Additionally, a coadded point spread function (PSF) model is established. Handling PSF coadding with care is crucial to ensure a well-defined PSF.\n",
    "\n",
    "One of the challenges in coadding PSFs arises from slight variations observed between PSFs in different visits. Even minor differences make it practically impossible to accurately model the effective PSF of the coadd using coadded star images. Even small positional shifts, known as dithers, used to fill the gaps between charge-coupled devices introduce disruptions in the effective PSF of the coadd. As the number of dithers increases, the areas within the coadd with a continuous effective PSF become smaller, making it increasingly unlikely to find stars suitable for PSF modeling in each region. For the Hyper-Suprime Camera survey, [Bosch et al 2018](https://ui.adsabs.harvard.edu/abs/2018PASJ...70S...5B/abstract) use an approach that involves resampling and combining existing PSF models from the input images using the same coordinate transformations and weights applied to the image data. The Hyper-Suprime Camera survey analysis pipeline is based on the LSST Science Pipelines code.\n",
    "\n",
    "[Mandelbaum et al. 2022](https://ui.adsabs.harvard.edu/abs/2023OJAp....6E...5M/abstract) provide a mathematical framework that aids in producing well-defined coadded PSFs. It's important to note that the results obtained using this approach are specifically applicable to static sources. As indicated in footnote 2 on page 3 of [Mandelbaum et al. 2022](https://ui.adsabs.harvard.edu/abs/2023OJAp....6E...5M/abstract), the coadd PSF for time-varying sources will vary depending on their light curves. For instance, if a variable or transient source appears very bright in just one exposure and faint in all others, its coadd PSF will essentially match that of the exposure where it is bright. This effect may introduce additional challenges for the LSST. The initial survey plan proposed using two 15-second \"snaps\" combined into a single 30-second exposure for each visit. Whether this approach will be implemented is still under consideration, but if adopted, the issue of PSF for time-varying objects in a coadd becomes relevant even in the process of combining the two snaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c76e3-37ee-4b18-9a3a-c6b1d9ea23f7",
   "metadata": {},
   "source": [
    "Visualize first the PSF model in a `deepCoadd` image similar to section 2.1, but this time using a `deepCoadd` image. \n",
    "\n",
    "Select the same point in the sky that we used to represent the PSF in the `calexp` of the previous section. \n",
    "\n",
    "This will allow us to better appreciate the differences between the `deepCoadd` and an individual `calexp` PSF model.\n",
    "\n",
    "First, retrieve the right ascension and declination coordinates of the point we used in the previous section (stored in the variable `point_tuple`), as well as the band of that exposure. Then, we will follow the steps outlined in section 3.2 of the Notebook tutorial `DP02_01` to determine the `tract` and `patch` of the `deepCoadd`. \n",
    "\n",
    "This information, along with the `band`, will uniquely define a data ID that we can provide to the butler to access the corresponding `deepCoadd`.\n",
    "\n",
    "This time, we will pass both the `tract` and `patch` numbers, along with the desired band (`i`), to uniquely specify the image we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a0a0f-d055-4d49-9035-56e33f76205d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = point_tuple\n",
    "ra, dec = wcs_calexp.pixelToSky(x, y)\n",
    "my_ra_deg = radToDeg(ra)\n",
    "my_dec_deg = radToDeg(dec)\n",
    "print(my_ra_deg, my_dec_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906ff57-a604-4984-89d9-72a509712727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_band = info_calexp.getFilter().bandLabel\n",
    "print(my_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba3928-01c2-4e95-8004-cc6f3191e47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_spherePoint = SpherePoint(my_ra_deg*degrees,\n",
    "                             my_dec_deg*degrees)\n",
    "print(my_spherePoint)\n",
    "\n",
    "skymap = butler.get('skyMap')\n",
    "\n",
    "tract = skymap.findTract(my_spherePoint)\n",
    "patch = tract.findPatch(my_spherePoint)\n",
    "\n",
    "my_tract = tract.tract_id\n",
    "my_patch = patch.getSequentialIndex()\n",
    "\n",
    "print('my_tract: ', my_tract)\n",
    "print('my_patch: ', my_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3806f9-de0a-42a0-bcfd-c8b122ce326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetType = 'deepCoadd'\n",
    "dataId = {'tract': my_tract, 'patch': my_patch, 'band': my_band}\n",
    "coadd = butler.get(datasetType, dataId=dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056a475-0ce7-48d5-8406-d7dfa7f7b198",
   "metadata": {},
   "source": [
    "The following plot is a 2D image of the `deepCoadd` from the previous butler query, in pixel coordinates ranging from 12000 to 16000 pixels in the horizontal axis and 0 to 4000 pixels in the vertical axis. The contrast bar ranges from negative 0.2 to 0.3 digital units. Point and extended sources are scattered around the image, however, a galaxy cluster is particularly prominent inthe lower left part of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bd8ff-5ea2-4e6f-a68d-3d688a4ed543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "display = afwDisplay.Display(frame=fig)\n",
    "display.scale('asinh', 'zscale')\n",
    "display.mtv(coadd.image)\n",
    "plt.title(f'deepCoadd. dataID: {dataId}')\n",
    "plt.xlabel('x (pix)')\n",
    "plt.ylabel('y (pix)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6148f6a-000d-49c8-b454-dd3d595869ac",
   "metadata": {},
   "source": [
    "In order to use the same point as in the example above with the `calexp`, we will retrieve first the WCS for the coadd information, and convert the sky point to local pixel coordinates in the `deepCoadd` image displayed in the previous cell.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f504fe9-b845-49f9-84ea-882e30531791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info_coadd = coadd.getInfo()\n",
    "wcs_coadd = info_coadd.getWcs()\n",
    "point_image = wcs_coadd.skyToPixel(my_spherePoint)\n",
    "point_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648e581-4bcd-4a76-847f-71477f3a9e9a",
   "metadata": {},
   "source": [
    "Use `computeKernelImage` to display the pixel-based model of the PSF at a particular point. Note the higher signal-to-noise ratio in this image, compared to the single `calexp` PSF image in Section 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9455bbb-1fa9-4ff7-860c-cc3223dbfefc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psf_coadd = info_coadd.getPsf()\n",
    "psf_kernel_coadd = psf_coadd.computeKernelImage(point_image)\n",
    "first_psf_image_coadd = psf_kernel_coadd.convertF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10997be2-331a-4ad2-ba1e-3bd3ecbcdda2",
   "metadata": {},
   "source": [
    "The following plot shows a postage stamp or cut-out of a PSF model from a `deepCoadd` image, obtained using `computeKernelImage`. The PSF is centered around zero, and the stamp is rectangular, with a size of about 50 pixels, ranging from -25 to 25 pixels on each size. The contrast bar ranges from -1e-5 to 7e-5 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d1c0c-d55f-47cb-acbe-109828b6a7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "afw_display = afwDisplay.Display()\n",
    "afw_display.scale('asinh', 'zscale')\n",
    "afw_display.mtv(first_psf_image_coadd)\n",
    "plt.title(f'PSF model in deepCoadd at {point_image} using computeKernelImage')\n",
    "plt.xlabel('x (pix)')\n",
    "plt.ylabel('y (pix)')\n",
    "plt.gca().axis('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18805e7-b26c-45c4-92c5-b9d1443003cc",
   "metadata": {},
   "source": [
    "Print the coordinates of the lower-left corner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d599ac-2c47-420b-8c9a-411fa34a4e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(first_psf_image_coadd.getXY0())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf24788-f26e-4b1c-8752-514bca1a3687",
   "metadata": {},
   "source": [
    "Now, instead of `computeKernelImage`, use\n",
    "`computeImage`. \n",
    "\n",
    "One has the PSF center at the center of the \n",
    "central pixel in the stamp or cutout (computeKernelImage), and \n",
    "the other one (computeImage) can make it at any arbitrary location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a116e4c-8108-445e-a5c3-fc07efe06b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_psf_image_coadd = psf_coadd.computeImage(point_image).convertF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bcd692-3b79-4793-8ff2-f1b0daa71771",
   "metadata": {},
   "source": [
    "The following plot shows a postage stamp or cut-out of a PSF model from a `deepCoadd` image, obtained using `computeImage`. The PSF is no longer centered around zero as when we used `computeKernelImage`, but centered at about 13000 and 2325 pixels. The stamp is still rectangular, with a size of about 50 pixels, ranging from 12970 to 12970 pixels on the horizantal axis and 2250 to 2350 on the vertical axis. The contrast bar ranges from negative 1e-5 to 7e-5 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17192f-b5d4-4817-8e11-ec0c2532d2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "afw_display = afwDisplay.Display()\n",
    "afw_display.scale('asinh', 'zscale')\n",
    "afw_display.mtv(second_psf_image_coadd)\n",
    "plt.title(f'PSF model in deepCoadd at {point_image} using computeImage')\n",
    "plt.xlabel('x (pix)')\n",
    "plt.ylabel('y (pix)')\n",
    "plt.gca().axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ea2b8-fd89-4ff2-ae9c-71b7090afd82",
   "metadata": {},
   "source": [
    "Look at the coordinates of the lower-left corner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f53d3-80d2-4d0b-9d76-766b2124d4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_psf_image_coadd.getXY0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c234d9a-f05e-4486-956b-8f01ab5c4720",
   "metadata": {},
   "source": [
    "Calculate the PSF properties, as in Section 2.1 for the `calexp` PSF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a0960-6a1e-4949-82c3-dd4ad5c7b547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "props_psf_coadd = get_psf_properties(psf_coadd, point_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92385ff5-cb7a-4670-9c04-d3df99b947cf",
   "metadata": {},
   "source": [
    "#### 2.3.  PSF properties for rapid analysis.\n",
    "\n",
    "In this section, we will utilize the `ImageExaminer` class that was introduced in section 1.2 of this tutorial. Our aim is to visualize the PSFs from both `calexp` and `deepCoadd` images discussed in sections 2.1 and 2.2. We will achieve this by employing surface and contour plots. Additionally, we will generate one-dimensional profiles of the central PSF along both the horizontal and vertical axes, along with creating an azimuthally-averaged radial profile of the PSF. We intend to fit a Gaussian function to this radial profile. Lastly, we will present a plot depicting the encircled flux as a function of radius. We will also showcase the results of fitting a Gaussian function to the radial profile, including parameters such as amplitude, size (Full-Width at Half-Maximum), and centroid, along with the radii corresponding to 50%, 80%, and 90% encircled fluxes.\n",
    "\n",
    "The code for this section is grounded in the [imageExaminer.py](https://github.com/lsst-sitcom/summit_utils/blob/main/python/lsst/summit/utils/imageExaminer.py) class. This class is currently employed for the [swift PSF analysis of the LATISS images](https://roundtable.lsst.codes/rubintv/summit/auxtel/im_current) obtained by Rubin's AuxTel at Cerro Pachón, Chile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d147ee5-9b54-46a1-976e-bbfd2925aa01",
   "metadata": {},
   "source": [
    "Let's now produce the plots for the`calexp` PSF of section 2.1. We'll start by making an instance of the `ImageExaminer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d5451-7da5-4df0-8b6f-a8e002aca14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psfImageExaminerCalexp = ImageExaminer(first_psf_image_calexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfee221-dc8f-47c0-86f0-9f442c7fd29f",
   "metadata": {},
   "source": [
    "The following cell will generate a plot comprising 6 panels, organized into 3 rows and 2 columns. In the upper left plot, a three-dimensional surface representation of the `calexp` PSF within the specified postage stamp range will be displayed. The upper right plot will present a two-dimensional contour plot showcasing the PSF centered at its core.\n",
    "\n",
    "Moving to the middle row, the left panel will provide a condensed overview of key statistics. These statistics will report the amplitude, width, and centroid derived from a one-dimensional Gaussian fit applied to the azimuthally averaged radial profile of the PSF. Furthermore, the panel will detail three encircled flux radii, corresponding to 50%, 80%, and 90% of the encircled flux, respectively. The right panel of this middle row will display the one-dimensional radial profiles. These profiles are formed by slicing the 2D PSF image along the central axes in both the horizontal and vertical directions.\n",
    "\n",
    "The left panel of the final row will depict the azimuthally averaged PSF radial profile, accompanied by a curve representing the Gaussian fit to the data. The right panel of this row will showcase a cumulative plot with a monotonically increasing curve, illustrating the percentage of encircled flux emanating from the PSF profile's center as a function of the radius in pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321883fa-967e-449f-9159-3849a947b149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotPsfImageExaminer(psfImageExaminerCalexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab2ef8-f327-4bcd-a81d-d95f8ba62c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T19:58:14.667760Z",
     "iopub.status.busy": "2023-07-05T19:58:14.666660Z",
     "iopub.status.idle": "2023-07-05T19:58:14.671131Z",
     "shell.execute_reply": "2023-07-05T19:58:14.670446Z",
     "shell.execute_reply.started": "2023-07-05T19:58:14.667728Z"
    },
    "tags": []
   },
   "source": [
    "And now let's do the plotting for the PSF from the `deppCoadd` of section 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76098b57-02a5-4aad-a022-6b9011bc0253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psfImageExaminerCoadd = ImageExaminer(first_psf_image_coadd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65152437-31ef-40f6-8eae-62e868211951",
   "metadata": {},
   "source": [
    "The upcoming cell will generate a plot featuring 6 panels, arranged in a grid with 3 rows and 2 columns. In the upper left plot, a three-dimensional surface representation of the `deepCoadd` PSF within the specified postage stamp range will be depicted. The upper right plot will display a two-dimensional contour representation of the PSF, centered at its core.\n",
    "\n",
    "Moving to the middle row, the left panel will encapsulate a summary of crucial statistics. These statistics encompass the amplitude, width, and centroid derived from a one-dimensional Gaussian fit applied to the azimuthally averaged radial profile of the PSF. Additionally, this panel will provide details about three encircled flux radii, corresponding to 50%, 80%, and 90% of the encircled flux, respectively. The right panel of this middle row will exhibit the one-dimensional radial profiles, constructed by slicing the 2D PSF image along the central axes in both horizontal and vertical directions.\n",
    "\n",
    "The left panel of the final row will visualize the azimuthally averaged PSF radial profile, alongside a curve resulting from the Gaussian fit to the data. The right panel of this row will showcase a cumulative plot with a monotonically increasing curve, illustrating the percentage of encircled flux originating from the center of the PSF profile as a function of radius in pixels. It's noteworthy that since the displayed PSF is a model built from coadded images, the plots and profiles exhibit a higher signal-to-noise ratio in comparison to the analogous plots from a previous cell, created for a `calexp` PSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ba901-73d9-4053-a5da-bb753540cfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotPsfImageExaminer(psfImageExaminerCoadd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff015e-70a2-49dc-9922-bf3b1d4a6019",
   "metadata": {},
   "source": [
    "#### 3. Size of the PSF and its correlation function using `treecorr`.\n",
    "\n",
    "In this section, our focus will be on plotting the size of the `deepCoadd` PSF in the `i` band as a function of celestial coordinates. To achieve this, we will utilize the TAP service to retrieve point sources from the `deepCoadd` catalog, along with the necessary parameters. Once we've calculated the PSF size based on the modeled PSF second moments, we will visualize it with respect to sky coordinates. \n",
    "\n",
    "Moreover, we will harness the capabilities of the `treecorr` software to compute the two-point correlation function of the size, considering angular separation as the variable of interest. Two-point correlation functions hold significant importance in weak lensing cosmological analysis, as they allow us to infer crucial cosmological parameters. Notably, `treecorr` serves as the standard tool employed by various collaborations, including the Dark Energy Survey and the Hyper-Suprime Camera Survey. It's also a prominent choice utilized by the LSST Science Pipelines code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55155865-6ffe-4a08-ab2d-6e9d9a4b3564",
   "metadata": {},
   "source": [
    "#### 3.1 Cone Search around the DC2 center using the `Object` catalog (`deepCoadd` images).  \n",
    "Let's conduct a cone search (similar to DP0.2 NB2) centered around the DC2 central point, with a search radius of 2 degrees. The query below utilizes the `Object` catalog, which houses the `deepCoadd` objects (refer to the [DP0.2 schema browser](https://dm.lsst.org/sdm_schemas/browser/dp02.html#Object)). Our query seeks PSF fluxes in various bands, derived from fitting a PSF model to a specific set of stars. We'll utilize the second moments of the PSF, denoted as `{band}_ixxPSF`, `{band}_ixyPSF`, and `{band}_iyyPSF`, to calculate the PSF size for each band.\n",
    "\n",
    "In this section, our focus is on plotting the PSF size exclusively in one band (`i`). However, in the subsequent section (section 4), we'll illustrate the relationship between PSF size and seeing by employing different bands. To identify point sources, we've set the flags `detect_isPrimary` and `i_extendedness` to 1 and 0.0, respectively. The presence of the `i_calib_psf_used` flag ensures our selection of stars that were utilized (rather than reserved) for establishing the PSF model (refer, for instance, to [Jarvis et al. 2020](https://ui.adsabs.harvard.edu/abs/2021MNRAS.501.1282J/abstract)).\n",
    "\n",
    "To ensure that the chosen objects aren't near edges, the `i_pixelFlags_inexact_psfCenter = 0` flag is employed. This choice is influenced by the fact that the `EDGE` flag in a `calexp` corresponds to the `SENSOR_EDGE` flag in the `coadd`. Objects near these edges have a discontinuous PSF. Additionally, the `inexact_psfCenter` results from an `OR` operation that includes `SENSOR_EDGE`. The other properties retrieved through the query will play a role in calculating the `rho` statistics, which will be the subject of section 5 in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e79ff-ae8e-4264-bfbe-56fadca407b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service = get_tap_service(\"tap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62fc337-86a5-4e90-ab35-c021647be8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_center_coords = \"62, -37\"\n",
    "band = 'i'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3706c4-e140-40df-8e64-99e54175de29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T15:10:33.730954Z",
     "iopub.status.busy": "2023-07-10T15:10:33.730073Z",
     "iopub.status.idle": "2023-07-10T15:10:33.736617Z",
     "shell.execute_reply": "2023-07-10T15:10:33.735310Z",
     "shell.execute_reply.started": "2023-07-10T15:10:33.730919Z"
    },
    "tags": []
   },
   "source": [
    "The following query could take more than a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06604b96-a0e8-4d5c-bb7c-0676a95d1788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = service.search(\"SELECT TOP 1000000\"\n",
    "                         \"coord_ra, coord_dec, \"\n",
    "                         \"scisql_nanojanskyToAbMag(u_psfFlux) as u_psfMag, \"\n",
    "                         \"scisql_nanojanskyToAbMag(g_psfFlux) as g_psfMag, \"\n",
    "                         \"scisql_nanojanskyToAbMag(r_psfFlux) as r_psfMag, \"\n",
    "                         \"scisql_nanojanskyToAbMag(i_psfFlux) as i_psfMag, \"\n",
    "                         f\"scisql_nanojanskyToAbMagSigma({band}_psfFlux, \"\n",
    "                         f\"{band}_psfFluxErr) \"\n",
    "                         f\"as {band}_psfMagErr, \"\n",
    "                         f\"{band}_psfFlux, \"\n",
    "                         f\"{band}_psfFlux_flag, \"\n",
    "                         f\"{band}_pixelFlags_saturatedCenter, \"\n",
    "                         f\"{band}_extendedness_flag, \"\n",
    "                         \"xy_flag, detect_isPatchInner, \"\n",
    "                         \"detect_isDeblendedSource, \"\n",
    "                         f\"{band}_psfFluxErr, {band}_extendedness, \"\n",
    "                         f\"{band}_ixy, {band}_ixyPSF, \"\n",
    "                         \"g_ixx, g_iyy, g_ixxPSF, g_iyyPSF, \"\n",
    "                         \"r_ixx, r_iyy, r_ixxPSF, r_iyyPSF, \"\n",
    "                         \"i_ixx, i_iyy, i_ixxPSF, i_iyyPSF, \"\n",
    "                         \"u_ixx, u_iyy, u_ixxPSF, u_iyyPSF  \"\n",
    "                         \"FROM dp02_dc2_catalogs.Object \"\n",
    "                         \"WHERE CONTAINS(POINT('ICRS', coord_ra, coord_dec), \"\n",
    "                         \"CIRCLE('ICRS', \"+use_center_coords+\", 2.0)) = 1 \"\n",
    "                         \"AND detect_isPrimary = 1 \"\n",
    "                         f\"AND {band}_calibFlux > 360 \"\n",
    "                         f\"AND {band}_extendedness = 0.0 \"\n",
    "                         f\"AND {band}_calib_psf_used = 1 \"\n",
    "                         f\"AND {band}_pixelFlags_inexact_psfCenter = 0 \")\n",
    "\n",
    "results_table = results.to_table().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8322c3-2883-482e-9089-8b057bf07b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(results_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14386853-59ce-497f-9e17-431ed0cbefef",
   "metadata": {},
   "source": [
    "##### 3.1.1 Size calculation, visualization, and two-point correlation function calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa600702-2204-430e-9f4f-e8f97ac5f65f",
   "metadata": {},
   "source": [
    "The trace of the moments matrix in each band, `T = {band}_ixxPSF + {band}_iyyPSF` will be used to calculate the \"trace radius\" (in pixels) `sqrt(T/2)` of the PSF model in each band, as a mesure of its size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d59d8-4854-42ff-9e59-56c38b89e44d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_table['size_g_PSF'] = np.sqrt((results_table['g_ixxPSF']\n",
    "                                       + results_table['g_iyyPSF']) / 2)\n",
    "results_table['size_r_PSF'] = np.sqrt((results_table['r_ixxPSF']\n",
    "                                       + results_table['r_iyyPSF']) / 2)\n",
    "results_table['size_i_PSF'] = np.sqrt((results_table['i_ixxPSF']\n",
    "                                       + results_table['i_iyyPSF']) / 2)\n",
    "results_table['size_u_PSF'] = np.sqrt((results_table['u_ixxPSF']\n",
    "                                       + results_table['u_iyyPSF']) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219e352-7f96-41c3-ab29-78835a8544cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ra = results_table['coord_ra']\n",
    "dec = results_table['coord_dec']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e16cc-4176-4f63-9bb0-60c2beaac87f",
   "metadata": {},
   "source": [
    "We will utilize the `treecorr` software ([Jarvis et al. 2015](https://ui.adsabs.harvard.edu/abs/2015ascl.soft08007J/abstract)) to compute the two-point correlation function of the PSF model size as a function of angular separation. In a broader sense, the two-point correlation function serves as a statistical metric that aids in comprehending the distribution and potential correlations of random variables within space or time.\n",
    "\n",
    "In astronomy, this function was introduced as a means to quantify the excess probability of locating two galaxies at a specific distance apart, as opposed to an expected uniform distribution ([Pebbles 1980](https://ui.adsabs.harvard.edu/abs/1980lssu.book.....P/abstract)). In modern galaxy surveys such as the Dark Energy Survey (DES), this tool is applied for cross-correlating key quantities like galaxy number counts and weak lensing shear in a \"3x2\" point analysis. This analysis methodology is employed to deduce constraints on cosmological parameters, and it's an approach that will also be adopted by the Large Synoptic Survey Telescope (LSST) (refer to [DES Collaboration 2022](https://ui.adsabs.harvard.edu/abs/2022PhRvD.105b3520A/abstract))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de61d34-d0ed-44aa-a380-98a90f19ec65",
   "metadata": {},
   "source": [
    "Let's define `treecorr`'s catalog and adjust a few of its parameters. For more information about `treecorr`, check its [documentation](https://rmjarvis.github.io/TreeCorr/_build/html/index.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0321df4-9cbd-4d54-9830-28bf0fb1a7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat = treecorr.Catalog(ra=ra, dec=dec,\n",
    "                       k=results_table[f'size_{band}_PSF']\n",
    "                       - np.mean(results_table[f'size_{band}_PSF']),\n",
    "                       ra_units='deg', dec_units='deg')\n",
    "\n",
    "kk_config = {'max_sep': .06, 'min_sep': .0001, 'nbins': 12}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18542a2-c4b1-4042-9b4d-750d78881c99",
   "metadata": {},
   "source": [
    "Let's now calculate the two-point correlation function of the size. In this case, this is an auto-correlation (size-size two point correlation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed6dee-6240-4875-a444-89f3eb8a7b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kk = treecorr.KKCorrelation(kk_config)\n",
    "kk.process(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099ebcb-9640-4f59-931e-3f9ed5a76fae",
   "metadata": {},
   "source": [
    "Retrieve the correlation function, denoted by `xi`, and the angular separation arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12e1e1-b2b1-4893-8308-655b9695943e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xi = kk.xi\n",
    "bins = kk.rnom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad3d23-1a9a-47bd-aaea-003c5ad1de0d",
   "metadata": {},
   "source": [
    "The figure generated by the following code cell consists of two panels. The left panel illustrates the PSF size within the investigated circle and band, as a function of declination (ranging from approximately negative 39 to negative 35 degrees) and right ascension (ranging from around 60 to 64 degrees). The PSF size or trace radius is depicted using a color scale, with values ranging from about 1.68 to 1.78 pixels.\n",
    "\n",
    "The right panel of the figure showcases the two-point autocorrelation function of the PSF size, plotted against angular separations in degrees. The correlation function values are expressed as multiples of 1e4, spanning from negative 1 to 0. Angular separations are marked on the abscissa axis, ranging from 0.01 to 2 degrees, and are represented on a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bd5ff-0213-4465-a22b-06241c254d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 4.5),\n",
    "                             gridspec_kw={'wspace': .3})\n",
    "\n",
    "ax1.set_title(f'PSF size. Band : {band}')\n",
    "scatter_plot = ax1.scatter(ra, dec, c=results_table[f'size_{band}_PSF'],\n",
    "                           s=1, cmap='cividis')\n",
    "ax1.set_xlabel('RA [deg]')\n",
    "ax1.set_ylabel('DEC [deg]')\n",
    "plt.colorbar(scatter_plot, ax=ax1, label='[pixels]')\n",
    "\n",
    "ax2.set_title(f'PSF size correlation. Band : {band}')\n",
    "ax2.plot(np.degrees(bins), xi*1e4, 'o-', color='darkblue')\n",
    "ax2.axhline(0, linestyle='--', color='lightgrey')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_ylabel(r'$\\xi \\times 10^{4}$', labelpad=-12)\n",
    "ax2.set_xlabel(r'$\\theta$ [degree]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b22d24-1ff7-4688-8938-d38092af4a96",
   "metadata": {},
   "source": [
    "#### 3.2 Cone Search around the DC2 center using the `Source` catalog (`calexp` images). \n",
    "\n",
    "Let's proceed to recreate the PSF size plot and correlation function, as computed in the previous cells. However, this time we will employ PSF models obtained from `calexp` images instead of `deepCoadd` images. This adjustment will allow us to observe the variation in PSF size within a visit, while still focusing on the `i` band. To achieve this, we'll make use of the `Source` catalog and make slight modifications to the query. Specifically, we will request only the columns that are relevant for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c793abf-5dfa-4224-b806-e89ec804eb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT TOP 500000\n",
    "            coord_ra, coord_dec,\n",
    "            ixy, ixyPSF,\n",
    "            ixx, iyy, ixxPSF, iyyPSF\n",
    "        FROM dp02_dc2_catalogs.Source\n",
    "        WHERE CONTAINS(POINT('ICRS', coord_ra, coord_dec),\n",
    "            CIRCLE('ICRS', %s, 2.0)) = 1\n",
    "            AND detect_isPrimary = 1\n",
    "            AND calibFlux > 360\n",
    "            AND extendedness = 0.0\n",
    "            AND calib_psf_used = 1\n",
    "            AND pixelFlags_suspectCenter = 0\n",
    "            AND band = '%s'\n",
    "        \"\"\" % (use_center_coords, band)\n",
    "\n",
    "results_source = service.search(query)\n",
    "\n",
    "results_table_source = results_source.to_table().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d8bd3-52a1-400e-a49f-fbcdc73196cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T19:34:18.123883Z",
     "iopub.status.busy": "2023-08-09T19:34:18.122837Z",
     "iopub.status.idle": "2023-08-09T19:34:18.288242Z",
     "shell.execute_reply": "2023-08-09T19:34:18.287618Z",
     "shell.execute_reply.started": "2023-08-09T19:34:18.123840Z"
    },
    "tags": []
   },
   "source": [
    "##### 3.2.1 Size calculation, visualization, and two-point correlation function calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db013cb9-af0f-44b7-b5d8-cdbe55b189dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = 0.5*(results_table_source['ixxPSF'] + results_table_source['iyyPSF'])\n",
    "results_table_source['size_i_PSF'] = np.sqrt(temp)\n",
    "\n",
    "ra_source = results_table_source['coord_ra']\n",
    "dec_source = results_table_source['coord_dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85aeb14-e189-496d-8aa1-3cc4982983a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat = treecorr.Catalog(ra=ra_source, dec=dec_source,\n",
    "                       k=results_table_source[f'size_{band}_PSF']\n",
    "                       - np.mean(results_table_source[f'size_{band}_PSF']),\n",
    "                       ra_units='deg', dec_units='deg')\n",
    "kk_config = {'max_sep': .06, 'min_sep': .0001, 'nbins': 12}\n",
    "kk = treecorr.KKCorrelation(kk_config)\n",
    "kk.process(cat)\n",
    "xi_source = kk.xi\n",
    "bins_source = kk.rnom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcdcbc8-f964-43ad-8fa3-bdc86ab1a796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 4.5),\n",
    "                             gridspec_kw={'wspace': .3})\n",
    "\n",
    "ax1.set_title(f'PSF size. Band : {band}')\n",
    "scatter_plot = ax1.scatter(ra_source, dec_source,\n",
    "                           c=results_table_source[f'size_{band}_PSF'],\n",
    "                           s=1, cmap='cividis')\n",
    "ax1.set_xlabel('RA [deg]')\n",
    "ax1.set_ylabel('DEC [deg]')\n",
    "plt.colorbar(scatter_plot, ax=ax1, label='[pixels]')\n",
    "\n",
    "ax2.set_title(f'PSF size correlation. Band : {band}')\n",
    "ax2.plot(np.degrees(bins_source), xi_source*1e4, 'o-', color='darkblue')\n",
    "ax2.axhline(0, linestyle='--', color='lightgrey')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_ylabel(r'$\\xi \\times 10^{4}$', labelpad=-12)\n",
    "ax2.set_xlabel(r'$\\theta$ [degree]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce500ff-0dee-46fd-962f-f6e2f399b399",
   "metadata": {},
   "source": [
    "The PSF size exhibits variations at both the tract level and individual visit level. It's important to note that there is no assurance that the sample retrieved from the aforementioned query will be spatially continuous; this may lead to the presence of noticeable gaps in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c700951-55c1-4875-ac01-78e10f115488",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Wavelength dependence of seeing  \n",
    "\n",
    "To correct for the effects of the Point Spread Function (PSF) and to deduce the weak lensing signal (referred to as \"shear\") from galaxy shapes, the PSF is typically modeled using stars, often bright ones. Subsequently, the PSF of galaxy images is deconvolved by utilizing the estimated PSF convolution kernel. Implicit in this methodology is the assumption that the convolution kernel for galaxies remains the same as that for stars. However, this assumption becomes invalid if the PSF varies with wavelength due to the distinctive Spectral Energy Distributions (SEDs) of stars and galaxies, resulting in disparate PSFs.\n",
    "\n",
    "In this section, we will leverage the point source sample derived from the `Object` catalog, which was obtained in the preceding sections. Our goal is to compute one of the wavelength-dependent components contributing to the PSF owing to atmospheric effects: the wavelength dependence on seeing. As per the standard theory of atmospheric turbulence, the linear dimension `θ` of the atmospheric convolution kernel (i.e., seeing) is inversely proportional to the wavelength, expressed as `θ ∝ λ**−1/5`.\n",
    "\n",
    "Additional wavelength-dependent contributions to the PSF encompass Differential Chromatic Refraction (DCR), telescope diffraction, variations in the absorption length of camera CCDs, and optical chromatic aberrations. In general, each of these factors exhibits distinct functional wavelength dependencies and may exert dominance in different spectral bands. Nevertheless, the wavelength-dependent seeing that we explore in this section tends to be the primary contributor to the PSF. These chromatic PSF effects introduce biases in observables such as photometry, astrometry, measurements of galaxy shape and size, and higher-order moments of the PSF. Addressing these effects is imperative for precise cosmological analysis employing weak gravitational lensing. For more detailed information, refer to the works of [Plazas and Bernstein 2012](https://ui.adsabs.harvard.edu/abs/2012PASP..124.1113P/abstract), [Lee et al. 2023](https://ui.adsabs.harvard.edu/abs/2023AJ....165..222L/abstract), [Meyers and Burchat 2015](https://ui.adsabs.harvard.edu/abs/2015ApJ...807..182M/abstract), [Tianqing et al. 2023](https://ui.adsabs.harvard.edu/abs/2023MNRAS.520.2328Z/abstract), and [Meyers and Burchat 2015b](https://ui.adsabs.harvard.edu/abs/2015JInst..10C6004M/abstract).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665398c4-00a4-44f6-abd3-e3122e71937d",
   "metadata": {},
   "source": [
    "To replicate this wavelength relationship using our data, we will initiate the process by computing the central wavelengths of the broadband filters employed by LSST, alongside determining the mean size and its standard deviation for each respective band. The boundaries of the filters are available in Table 2.1 of the [LSST Science Book](https://ui.adsabs.harvard.edu/abs/2009arXiv0912.0201L/abstract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371d2cc-a861-43e3-89a1-2d986ba34f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wavelength = 0.5*np.array([320+400, 400+552, 552+691, 691+818])\n",
    "\n",
    "mean_size = [np.mean(results_table['size_u_PSF']),\n",
    "             np.mean(results_table['size_g_PSF']),\n",
    "             np.mean(results_table['size_r_PSF']),\n",
    "             np.mean(results_table['size_i_PSF'])]\n",
    "\n",
    "std_size = [np.std(results_table['size_u_PSF']),\n",
    "            np.std(results_table['size_g_PSF']),\n",
    "            np.std(results_table['size_r_PSF']),\n",
    "            np.std(results_table['size_i_PSF'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1dc1a3-11f5-4eb0-993e-b27e878c3b06",
   "metadata": {},
   "source": [
    "We will proceed to fit a power law to the mean PSF size in relation to wavelength by employing [`scipy.optimize.curvefit`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html). This function takes the functional form to be fitted as its first argument, followed by two arrays containing the data. The output is a tuple consisting of the optimized parameters that minimize the squared residuals of the function with respect to the measured data, labeled as `popt`. Additionally, it provides the estimated 2D covariance matrix of the fitted parameters, denoted as `pcov`, wherein the diagonal elements offer an estimation of their respective one-standard-deviation errors (for more comprehensive information, refer to [the documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e6234-d4da-48e0-874a-b0c64f793bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(power, wavelength, mean_size)\n",
    "perr = np.sqrt(np.diag(pcov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450779bf-77bf-42c5-9805-297985790b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lamb_grid = np.arange(300, 800, 1)\n",
    "fit_size = power(lamb_grid, *popt)\n",
    "amplitude, exponent = popt\n",
    "amplitude_error, exponent_error = perr\n",
    "print(f\"Amplitude: {amplitude:.3} +/- {amplitude_error:.3}\")\n",
    "print(f\"Exponent: {exponent:.3} +/- {exponent_error:.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b9ee6-ee39-4ff3-8ae7-f8675fc129cb",
   "metadata": {},
   "source": [
    "The fitted exponent, `-0.196 +/- 0.0235` is within one-sigma of the expected value of `-1/5=0.2`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841e9fa-406c-4b17-bce9-1f9d2d9025f3",
   "metadata": {},
   "source": [
    "The upcoming code cell will generate a plot depicting the mean PSF size (expressed as the trace radius in pixels) in relation to the central wavelength for the previously specified LSST filters. Additionally, a power law fit will be presented on the same plot, with the associated amplitude and fitting parameters indicated within the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb842f4-1a74-4d21-bb83-06236a0ee812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.errorbar(wavelength, mean_size, std_size/np.sqrt(len(results_table)),\n",
    "             fmt='o--', label='data')\n",
    "plt.plot(lamb_grid, fit_size,\n",
    "         label=r'$\\theta = %.3f \\lambda^{%.3f}$' % (amplitude, exponent))\n",
    "plt.title(\"Seeing dependence on wavelength.\")\n",
    "plt.xlabel(r'$\\lambda$ (nm)')\n",
    "plt.ylabel(r'$\\sqrt{(Ixx+Iyy)/2}$ (pixel)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2906b27f-96fc-4b78-bbee-9f413856960e",
   "metadata": {},
   "source": [
    "In the forthcoming figure, we will superimpose the size distributions per band onto the previously generated plot. The figure includes histograms of the size distributions corresponding to each band (`u`, `g`, `r`, and `i`), rotated 270 degrees to align their bases with the left vertical axis. The upper horizontal axis will display the histogram counts, spanning from 0 to approximately 1200 counts. Notably, this plot serves a dual role, as it incorporates both the data for the PSF size as a function of wavelength and the power-law fit from the preceding plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da64b0-7505-43d6-adcb-12ff8d1a393b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel(r'$\\lambda$ (nm)')\n",
    "ax1.set_ylabel(r'$\\sqrt{(Ixx+Iyy)/2}$ (pixel)')\n",
    "ax1.errorbar(wavelength, mean_size, std_size/np.sqrt(len(results_table)),\n",
    "             fmt='o--', label='data')\n",
    "ax1.plot(lamb_grid, fit_size,\n",
    "         label=r'$\\theta = %.3f \\lambda^{%.3f}$' % (amplitude, exponent))\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "plot_filter_colors = {'u': '#56b4e9', 'g': '#008060', 'r': '#ff4000',\n",
    "                      'i': '#850000', 'z': '#6600cc', 'y': '#000000'}\n",
    "\n",
    "ax2.set_xlabel('counts')\n",
    "plt.hist(results_table['size_u_PSF'], bins=100, range=[1.6, 2.2],\n",
    "         color=plot_filter_colors['u'], alpha=0.3, label='u',\n",
    "         orientation=\"horizontal\")\n",
    "plt.hist(results_table['size_g_PSF'], bins=100, range=[1.6, 2.2],\n",
    "         color=plot_filter_colors['g'], alpha=0.3, label='g',\n",
    "         orientation=\"horizontal\")\n",
    "plt.hist(results_table['size_r_PSF'], bins=100, range=[1.6, 2.2],\n",
    "         color=plot_filter_colors['r'], alpha=0.3, label='r',\n",
    "         orientation=\"horizontal\")\n",
    "plt.hist(results_table['size_i_PSF'], bins=100, range=[1.6, 2.2],\n",
    "         color=plot_filter_colors['i'], alpha=0.3, label='i',\n",
    "         orientation=\"horizontal\")\n",
    "plt.legend()\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fecd7f-018f-48df-ba9d-45e96a4b4801",
   "metadata": {},
   "source": [
    "### 5. Rho Statistics with Analysis Tools\n",
    "\n",
    "In this section, we will utilize [`lsst.analysis.tools`](https://github.com/lsst/analysis_tools) to compute the `rho` statistics, which are a collection of two-point correlation functions used to assess the spatial relationships between errors in PSF models. The presence of non-zero values in these statistics signifies the existence of systematic errors in the weak lensing shear correlation function. To understand their definitions, refer to [the analysis tools documentation](https://pipelines.lsst.io/v/daily/py-api/lsst.analysis.tools.actions.vector.CalcRhoStatistics.html#lsst.analysis.tools.actions.vector.CalcRhoStatistics). \n",
    "\n",
    "`lsst.analysis.tools` is a package designed to generate quality assurance (QA) plots and metrics from the outputs of the LSST Science Pipelines. It employs `treecorr` to compute the `rho` statistics. For an introductory demonstration of `analysis_tools`, you can refer to [this Jupyter Notebook created for a session during Rubin's 2022 Project and Community Workshop](https://github.com/lsst-dm/analysis_tools_examples/blob/main/analysis_tools_demo_pcw2022.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639a047-d86b-4540-b897-54564189bf3f",
   "metadata": {},
   "source": [
    "We will begin by creating the `RhoStatistics` analysis structure using the `AnalysisTool`. As outlined in the [2020 Rubin PCW `analysis_tools` demo notebook](https://github.com/lsst-dm/analysis_tools_examples/blob/main/analysis_tools_demo_pcw2022.ipynb), the `AnalysisTool` is one of the three analysis structures provided by `analysis_tools`. It encompasses several `AnalysisAction` components, which collectively conduct specific types of analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa13319-c6b5-4c42-a6f4-21eacfb7ad23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atool = RhoStatistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd3266-2af3-4712-89f8-17795abf216d",
   "metadata": {},
   "source": [
    "There are three types of `AnalysisAction`s or stages: `prep` (for initial filtering of data), `process` (for modyfing the data), and `produce` (for generating final plots of metrics). In the following cells, we will adjust a few configuration parameters from the `prep` and `process` stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ad2b6-b872-45ff-9bba-1c06ed30d59f",
   "metadata": {},
   "source": [
    "We'll start with selecting stars with with signal-to-noise ratio (SNR) > 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b60d5c-0529-4e76-bf0e-4be4b81ac22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atool.prep.selectors.snSelector.threshold = 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295e266-f0a9-4c7b-ab3a-23b144e8cfc0",
   "metadata": {},
   "source": [
    "As in a previous section, we can adjust the `treecorr` parameters before calculations, but this time it will be done via `lsst.analysis.tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47bb00f-b4e5-4525-a259-1b1831440f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atool.process.calculateActions.rho.treecorr.nbins = 21\n",
    "atool.process.calculateActions.rho.treecorr.min_sep = 0.1\n",
    "atool.process.calculateActions.rho.treecorr.max_sep = 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4b77d-4ed0-4354-8057-6ec0867df185",
   "metadata": {},
   "source": [
    "We need to call `atool.finalize()` after the `atool.prep` and `atool.process` stages are configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff3bbe-bfde-4756-b149-1e63c3c0e247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atool.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8f06d-be02-45c1-ba24-76ddf93de7a0",
   "metadata": {},
   "source": [
    "The TAP query in section 3.1 included fields that we did not use in that section, but that will be used in this section. In order to know which entries will be needed by `analysys_tools` to calculate the `rho` statistics, we can look at the input schema of the analysis tool `RhoStatistics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8b391-dbf1-451f-b6da-e5c25adfacd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_schema = atool.getInputSchema()\n",
    "needed_catalog_fields = [name[0] for name in list(atool.getInputSchema())]\n",
    "print(needed_catalog_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea9678-00bd-4b5c-8b5e-3f7394dd0670",
   "metadata": {},
   "source": [
    "Now we are ready to compute the `rho` statistics in the particular band that we have chosen previously (`i`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711b878-1e1c-427e-8405-34f56c663e5b",
   "metadata": {},
   "source": [
    "\n",
    "We'll start with the `prep` stage in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876cc98-a846-4bb7-9adb-0f1aaff0e9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepResults = atool.prep(results_table, band=f\"{band}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201731f-83eb-4205-8765-a832f5c57a65",
   "metadata": {},
   "source": [
    "Now we will execute the `process` stage, utilizing the outcomes obtained from the `prep` stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92dd649-59f2-40b4-861c-4b94b9b04be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processResults = atool.process(prepResults, band=f\"{band}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdc877-1f65-4c90-b8d7-29aa052c60b5",
   "metadata": {},
   "source": [
    "We can now access the results from `treecorr` for each `rho` statistic in order to examine the values or perform any other operation on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7d5d0-43fe-48e2-a56a-ec844a7a82d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Mean angular separation:\\n\", processResults['rho1'].meanr, \"\\n\")\n",
    "print(\"Correlation function:\\n\", processResults['rho1'].xip, \"\\n\")\n",
    "print(\"Error in the correlation function:\\n\", processResults['rho1'].varxip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f3aae-5c3d-4d28-89a7-088de01b97e4",
   "metadata": {},
   "source": [
    "Let's now plot the `rho` statistics using `analysis_tools`: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d0cbac-2701-4604-8b07-586dc7e1455a",
   "metadata": {},
   "source": [
    "By default, the rho statistics are plotted on a symmetric log scale.\n",
    "The threshold where the switch happens from linear to log scale can be set as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400821f2-f4ce-4012-8886-071a5cdd7644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atool.produce.plot.rhoPlots[\"rho3\"].yLinThresh = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea3e87-d27e-4a2f-8717-33a5d961a41b",
   "metadata": {},
   "source": [
    "The following cell will produce six plots of the `rho` statistics. For other possible configuration options, you can refer to the documentation [here](https://pipelines.lsst.io/v/daily/py-api/lsst.analysis.tools.actions.plot.XYPlot.html#lsst.analysis.tools.actions.plot.XYPlot). The vertical axis of each plot displays the specific `rho` statistic, and the horizontal axis represents the separation in arcminutes, ranging from approximately 0.01 to 100 arcminutes on a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19ba4b-a4a0-4da8-b986-e496e978fd5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "produceResults = atool.produce(processResults, band=f\"{band}\", skymap=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2229b46-2a92-4596-8021-837afb6f844d",
   "metadata": {},
   "source": [
    "As explained in [Jarvis et al. 2020](https://ui.adsabs.harvard.edu/abs/2021MNRAS.501.1282J/abstract), `rho1` (ρ1), `rho3` (ρ3), and `rho4` (ρ4) represent direct systematic errors in `xi+` (ξ+) with leading coefficients of order unity. `rho2` (ρ2) and `rho5` (ρ5) describe the extent of \"PSF leakage\" that occurs during the shear measurement process.\n",
    "\n",
    "The DC2 area is relatively small and does not exhibit significant PSF variations. The `rho` statistics obtained in the previous examples (for the `i` band, considering that `rho` statistics can vary with different bands) are relatively small and well-behaved. For comparison, you can refer to Figure 26 of the [HSC Y3 shape catalog](https://ui.adsabs.harvard.edu/abs/2022PASJ...74..421L/abstract) and Figure 12 of the [DES Y3 shape catalog analyses](https://ui.adsabs.harvard.edu/abs/2021MNRAS.501.1282J/abstract), which display `rho` statistics obtained from on-sky data from their respective galaxy surveys (HSC Survey and DES). These figures also include the requirements that each `rho` statistic should satisfy (e.g., Eq. 37 of [Li et al. 2021](https://ui.adsabs.harvard.edu/abs/2022PASJ...74..421L/abstract)) to ensure that there are no significant PSF modeling systematic errors that would impact the scientific goals related to cosmic shear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3ff6f-07cb-41f5-b884-f4ca9d623c24",
   "metadata": {},
   "source": [
    "### Exercises for the Learner\n",
    "\n",
    "#### Section 2:\n",
    "\n",
    "* a) In the `radialAverageAndFit` function of the `ImageExaminer` class, try using a different functional form for fitting the one-dimensional PSF radial profiles, such as the Moffat profile (as described in Eq. 3.6 of [Jarvis et al. 2020](https://ui.adsabs.harvard.edu/abs/2021MNRAS.501.1282J/abstract)).\n",
    "\n",
    "* b) Extend the analysis of the one-dimensional PSF radial profiles by calculating additional statistics such as skewness and kurtosis, and visualize them to gain insights into the PSF behavior.\n",
    "\n",
    "#### Section 3:\n",
    "* a) Calculate the PSF ellipticity using the definition based on the second moments, as described in Eq. 7.5 of [Jarvis et al. 2020](https://ui.adsabs.harvard.edu/abs/2021MNRAS.501.1282J/abstract). Create plots similar to those in section 3.2 to visualize the PSF ellipticity variation across the image.\n",
    "\n",
    "* b) Modify the query in section 3.1 to retrieve both point sources and extended sources. Create a size-magnitude diagram using the definition of size from section 3.2. Identify the region in the diagram where the size is constant, representing likely stars during the star-galaxy separation process. Compare your results with Figure 3 in [Jarvis et al. 2020](https://ui.adsabs.harvard.edu/abs/2021MNRAS.501.1282J/abstract).\n",
    "\n",
    "#### Section 5: \n",
    "* a) Modify the query in section 3.1 to retrieve the required catalog fields according to the input schema for the `RhoStatistics` of `analysis_tools`. Calculate the `rho` statistics for a different band, such as the `g` band. Note that chromatic effects, including Differential Chromatic Refraction (DCR) and wavelength-dependent seeing, have a larger impact in the bluer bands. Use the `rho` statistics as a diagnostic tool to assess whether observations in these bluer bands should be included in weak lensing analyses (refer to the discussion in section 7.4 of [Jarvis et al. 2020](https://ui.adsabs.harvard.edu/abs/2021MNRAS.501.1282J/abstract)).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
